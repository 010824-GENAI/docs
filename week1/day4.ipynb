{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 4: Word2Vec, Text Similarity, Hugging Face\n",
    "\n",
    "## Agenda\n",
    "- Word Embeddings: Word2Vec\n",
    "- Text Similarity: Cosine Similarity, Jaccard Similarity\n",
    "- Introduction to HuggingFace Transformers Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embeddings\n",
    "- Humans are good with words. Computers are good with numbers\n",
    "  - Look at the evolution of programming languages\n",
    "- Word Embedding is a vector representation of words (more precisely, vector representation)\n",
    "- This allows computers to tell how 2 texts are similar/dissimilar from each other\n",
    "\n",
    "- 2 popular techniques: Word2Vec, GloVe\n",
    "  - Word2Vec: \"two words sharing similar contexts also share a similar meaning\"\n",
    "  - GloVe: \"Gloval Vectors for Word Representation\"\n",
    "\n",
    "Library Gensim provides Word2Vec implementation which we'll use to explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "w2v = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Out of total {len(w2v.index_to_key)} words\")\n",
    "for index, word in enumerate(w2v.index_to_key):\n",
    "    if index <= 10:\n",
    "        print(f\"#{index}: {word}\")\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_computer = w2v['computer']\n",
    "print(vec_computer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v['revature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [\n",
    "    # Going from more similar to less similar \n",
    "    ('cup', 'mug'),\n",
    "    ('cup', 'bowl'),  \n",
    "    ('cup', 'beverage'),\n",
    "    ('cup', 'cat'),  \n",
    "]\n",
    "for w1, w2 in pairs:\n",
    "    print('%r\\t%r\\t%.2f' % (w1, w2, w2v.similarity(w1, w2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(w2v.most_similar(positive=['cup', 'mug'], topn=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(w2v.doesnt_match(['cup', 'cat', 'mug', 'jar']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Similarity: Cosine Similarity, Jaccard Similarity\n",
    "\n",
    "- Techniques like Word2Vec and GloVe gives us mathematical representations of texts, but how do they tell how similar/dissimilar they are?\n",
    "- Different Techniques:\n",
    "    - Euclidean Distance (how far apart are these vectors?)\n",
    "    - Cosine Similarity (The angle between the vectors)\n",
    "    - Jaccard Similarity (How many words do these texts share?)\n",
    "    - and more\n",
    "\n",
    "### Cosine Similarity\n",
    "One of the most common techniques. We calculate the angle between the two vectors.\n",
    "![cos_sim](https://memgraph.com/images/blog/cosine-similarity-python-scikit-learn/cosine-similarity.png)\n",
    "![cos_sim_formula](https://assets-global.website-files.com/5ef788f07804fb7d78a4127a/60dee7e4dec6611dc63cb158_dNiiYIrknDdfDwnqRpJ4n23givOOrrkWvlsBED9hE7qahtn_itdM1ziLQm0YYmqlV2j5q1Kur_icFc_K1jyYKIAcz_PBZ32OjpaFVQGAf41K3O0PhVRnnROFNnb_04jQ36VcX8pF.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install scikit-learn\n",
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "\n",
    "# This is a python implementation of cosine similarity, using numpy\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    if len(vec1) != len(vec2) :\n",
    "        return None\n",
    "    \n",
    "    # Compute the dot product between 2 vectors\n",
    "    dot_prod = np.dot(vec1, vec2)\n",
    "    \n",
    "    # Compute the norms of the 2 vectors\n",
    "    norm_vec1 = np.sqrt(np.sum(vec1**2)) \n",
    "    norm_vec2 = np.sqrt(np.sum(vec2**2))\n",
    "    \n",
    "    # Compute the cosine similarity\n",
    "    # We divide the dot product of the 2 vectors by their length\n",
    "    cosine_similarity = dot_prod / (norm_vec1 * norm_vec2)\n",
    "    \n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample texts\n",
    "text1 = \"Natural language processing is fascinating.\"\n",
    "text2 = \"I'm intrigued by the wonders of natural language processing.\"\n",
    "\n",
    "# Tokenize and vectorize the texts\n",
    "vectorizer = CountVectorizer().fit_transform([text1, text2]).toarray()\n",
    "print(vectorizer)\n",
    "\n",
    "# Calculate cosine similarity\n",
    "cosine_sim = cosine_similarity(vectorizer[0, :], vectorizer[1, :])\n",
    "\n",
    "# Cosine Similarity ranges from -1 to 1, a number closer to 1 means that they are more similar\n",
    "print(\"Cosine Similarity:\")\n",
    "print(cosine_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaccard Index\n",
    "Jaccard Index, or Jaccard similarity coefficient, is used to guage the similarity between two sets.\n",
    "\n",
    "![jc_idx](https://wikimedia.org/api/rest_v1/media/math/render/svg/eaef5aa86949f49e7dc6b9c8c3dd8b233332c9e7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(set1, set2):\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "    return intersection / union if union != 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "text1 = \"Natural language processing is fascinating.\"\n",
    "text2 = \"I'm intrigued by the wonders of natural language processing.\"\n",
    "\n",
    "# Tokenize the sentences and turn them into sets\n",
    "set1 = set(word_tokenize(text1))\n",
    "set2 = set(word_tokenize(text2))\n",
    "\n",
    "# Calculate Jaccard similarity\n",
    "jaccard_sim = jaccard_similarity(set1, set2)\n",
    "\n",
    "# Print the Jaccard similarity\n",
    "print(f\"Jaccard Similarity: {jaccard_sim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HuggingFace\n",
    "- A company that focuses on fostering an open-source AI/ML community.\n",
    "- Originally a chatbot company built for teenagers (perhaps, hence the name and emoji) \n",
    "- Famous for their massive open-source collection of AI models and Transformer library\n",
    "- The platform we'll be using for our LLM's and Text Embedding Models.\n",
    "\n",
    "### Transformer Library\n",
    "- Library built for easy, low barrier interaction with various AI models\n",
    "- Transformer refers to a specific type of text-generation model that are context aware (like BERT or GPT), BUT in this context, HuggingFace's Transformer library has models beyond text-generation.\n",
    "- Benefits: Ease of Use, Flexibility, Simplicity\n",
    "- Tutorial: https://huggingface.co/learn/nlp-course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "# Got a windows machine and ran into an ERROR for not enabling long path? Run this line on PowerShell\n",
    "New-ItemProperty -Path \"HKLM:\\SYSTEM\\CurrentControlSet\\Control\\FileSystem\" `\n",
    "-Name \"LongPathsEnabled\" -Value 1 -PropertyType DWORD -Force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(\"I pulled 3 all nighters for this project. I'm so exhausted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember Tokenizing from the last 2 days?\n",
    "Well, we can't feed the models the raw text, so we have to tokenize our raw text the exact way the model was trained/expecting to receive input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "raw_inputs = [\n",
    "    \"I've been waiting for this weekend this whole month.\",\n",
    "    \"I hate this so much!\",\n",
    "]\n",
    "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"tf\")\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "text_generator = pipeline(\"text-generation\")\n",
    "generated_text = text_generator(\"This weekend is three day weekend! I am going to\")[0]['generated_text']\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "long_text = \"\"\"\n",
    "In recent years, artificial intelligence (AI) has witnessed remarkable advancements, particularly in the field of natural language processing (NLP). Researchers and developers have made significant strides in creating sophisticated models that can understand and generate human-like text. One notable breakthrough is the development of transformer-based architectures, such as BERT and GPT-3, which have set new benchmarks in various NLP tasks.\n",
    "\n",
    "These models excel in tasks like sentiment analysis, text summarization, and language translation, showcasing their versatility. The widespread adoption of transformer models has led to the emergence of powerful tools and libraries, like the Transformers library by Hugging Face, making it easier for practitioners to leverage state-of-the-art models for their applications.\n",
    "\n",
    "However, the rapid progress in AI and NLP also raises ethical concerns and challenges. Issues like bias in language models, transparency in decision-making processes, and potential misuse of powerful AI technologies need careful consideration. As the field continues to evolve, striking a balance between innovation and ethical responsibility becomes crucial.\n",
    "\n",
    "In conclusion, the recent advancements in NLP, driven by transformer models and accessible libraries, have transformed the landscape of AI. While these technologies offer unprecedented capabilities, the ethical implications and responsible use of AI demand ongoing attention from the global community.\n",
    "\"\"\"\n",
    "summarizer = pipeline(\"summarization\")\n",
    "summary = summarizer(long_text)[0]['summary_text']\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other ways to use HuggingFace\n",
    "\n",
    "#### Hugging Face Inference API\n",
    "Hugging Face Inference API and Endpoint gives us access to the models hosted on huggingface via simple HTTP calls.\n",
    "Subtle but annoying Difference: HuggingFace Inference API: free version. HuggingFace Inference Endpoint: Paid, your own huggingface infra\n",
    "\n",
    "https://huggingface.co/spaces/HuggingFaceH4/zephyr-chat\n",
    "\n",
    "https://huggingface.co/HuggingFaceH4/zephyr-7b-beta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
