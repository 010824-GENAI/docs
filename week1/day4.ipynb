{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 4: Word2Vec, Text Similarity, Hugging Face\n",
    "\n",
    "## Agenda\n",
    "- Word Embeddings: Word2Vec\n",
    "- Text Similarity: Cosine Similarity, Jaccard Similarity\n",
    "- Introduction to HuggingFace Transformers Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embeddings\n",
    "- Humans are good with words. Computers are good with numbers\n",
    "  - Look at the evolution of programming languages\n",
    "- Word Embedding is a vector representation of words (more precisely, vector representation)\n",
    "- This allows computers to tell how 2 texts are similar/dissimilar from each other\n",
    "\n",
    "- 2 popular techniques: Word2Vec, GloVe\n",
    "  - Word2Vec: \"two words sharing similar contexts also share a similar meaning\"\n",
    "  - GloVe: \"Global Vectors for Word Representation\"\n",
    "\n",
    "Library Gensim provides Word2Vec implementation which we'll use to explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "# Pre-trained model using word2vec on google news dataset\n",
    "w2v = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of total 3000000 words\n",
      "#0: </s>\n",
      "#1: in\n",
      "#2: for\n",
      "#3: that\n",
      "#4: is\n",
      "#5: on\n",
      "#6: ##\n",
      "#7: The\n",
      "#8: with\n",
      "#9: said\n",
      "#10: was\n"
     ]
    }
   ],
   "source": [
    "print(f\"Out of total {len(w2v.index_to_key)} words\")\n",
    "for index, word in enumerate(w2v.index_to_key):\n",
    "    if index <= 10:\n",
    "        print(f\"#{index}: {word}\")\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.07421875e-01 -2.01171875e-01  1.23046875e-01  2.11914062e-01\n",
      " -9.13085938e-02  2.16796875e-01 -1.31835938e-01  8.30078125e-02\n",
      "  2.02148438e-01  4.78515625e-02  3.66210938e-02 -2.45361328e-02\n",
      "  2.39257812e-02 -1.60156250e-01 -2.61230469e-02  9.71679688e-02\n",
      " -6.34765625e-02  1.84570312e-01  1.70898438e-01 -1.63085938e-01\n",
      " -1.09375000e-01  1.49414062e-01 -4.65393066e-04  9.61914062e-02\n",
      "  1.68945312e-01  2.60925293e-03  8.93554688e-02  6.49414062e-02\n",
      "  3.56445312e-02 -6.93359375e-02 -1.46484375e-01 -1.21093750e-01\n",
      " -2.27539062e-01  2.45361328e-02 -1.24511719e-01 -3.18359375e-01\n",
      " -2.20703125e-01  1.30859375e-01  3.66210938e-02 -3.63769531e-02\n",
      " -1.13281250e-01  1.95312500e-01  9.76562500e-02  1.26953125e-01\n",
      "  6.59179688e-02  6.93359375e-02  1.02539062e-02  1.75781250e-01\n",
      " -1.68945312e-01  1.21307373e-03 -2.98828125e-01 -1.15234375e-01\n",
      "  5.66406250e-02 -1.77734375e-01 -2.08984375e-01  1.76757812e-01\n",
      "  2.38037109e-02 -2.57812500e-01 -4.46777344e-02  1.88476562e-01\n",
      "  5.51757812e-02  5.02929688e-02 -1.06933594e-01  1.89453125e-01\n",
      " -1.16210938e-01  8.49609375e-02 -1.71875000e-01  2.45117188e-01\n",
      " -1.73828125e-01 -8.30078125e-03  4.56542969e-02 -1.61132812e-02\n",
      "  1.86523438e-01 -6.05468750e-02 -4.17480469e-02  1.82617188e-01\n",
      "  2.20703125e-01 -1.22558594e-01 -2.55126953e-02 -3.08593750e-01\n",
      "  9.13085938e-02  1.60156250e-01  1.70898438e-01  1.19628906e-01\n",
      "  7.08007812e-02 -2.64892578e-02 -3.08837891e-02  4.06250000e-01\n",
      " -1.01562500e-01  5.71289062e-02 -7.26318359e-03 -9.17968750e-02\n",
      " -1.50390625e-01 -2.55859375e-01  2.16796875e-01 -3.63769531e-02\n",
      "  2.24609375e-01  8.00781250e-02  1.56250000e-01  5.27343750e-02\n",
      "  1.50390625e-01 -1.14746094e-01 -8.64257812e-02  1.19140625e-01\n",
      " -7.17773438e-02  2.73437500e-01 -1.64062500e-01  7.29370117e-03\n",
      "  4.21875000e-01 -1.12792969e-01 -1.35742188e-01 -1.31835938e-01\n",
      " -1.37695312e-01 -7.66601562e-02  6.25000000e-02  4.98046875e-02\n",
      " -1.91406250e-01 -6.03027344e-02  2.27539062e-01  5.88378906e-02\n",
      " -3.24218750e-01  5.41992188e-02 -1.35742188e-01  8.17871094e-03\n",
      " -5.24902344e-02 -1.74713135e-03 -9.81445312e-02 -2.86865234e-02\n",
      "  3.61328125e-02  2.15820312e-01  5.98144531e-02 -3.08593750e-01\n",
      " -2.27539062e-01  2.61718750e-01  9.86328125e-02 -5.07812500e-02\n",
      "  1.78222656e-02  1.31835938e-01 -5.35156250e-01 -1.81640625e-01\n",
      "  1.38671875e-01 -3.10546875e-01 -9.71679688e-02  1.31835938e-01\n",
      " -1.16210938e-01  7.03125000e-02  2.85156250e-01  3.51562500e-02\n",
      " -1.01562500e-01 -3.75976562e-02  1.41601562e-01  1.42578125e-01\n",
      " -5.68847656e-02  2.65625000e-01 -2.09960938e-01  9.64355469e-03\n",
      " -6.68945312e-02 -4.83398438e-02 -6.10351562e-02  2.45117188e-01\n",
      " -9.66796875e-02  1.78222656e-02 -1.27929688e-01 -4.78515625e-02\n",
      " -7.26318359e-03  1.79687500e-01  2.78320312e-02 -2.10937500e-01\n",
      " -1.43554688e-01 -1.27929688e-01  1.73339844e-02 -3.60107422e-03\n",
      " -2.04101562e-01  3.63159180e-03 -1.19628906e-01 -6.15234375e-02\n",
      "  5.93261719e-02 -3.23486328e-03 -1.70898438e-01 -3.14941406e-02\n",
      " -8.88671875e-02 -2.89062500e-01  3.44238281e-02 -1.87500000e-01\n",
      "  2.94921875e-01  1.58203125e-01 -1.19628906e-01  7.61718750e-02\n",
      "  6.39648438e-02 -4.68750000e-02 -6.83593750e-02  1.21459961e-02\n",
      " -1.44531250e-01  4.54101562e-02  3.68652344e-02  3.88671875e-01\n",
      "  1.45507812e-01 -2.55859375e-01 -4.46777344e-02 -1.33789062e-01\n",
      " -1.38671875e-01  6.59179688e-02  1.37695312e-01  1.14746094e-01\n",
      "  2.03125000e-01 -4.78515625e-02  1.80664062e-02 -8.54492188e-02\n",
      " -2.48046875e-01 -3.39843750e-01 -2.83203125e-02  1.05468750e-01\n",
      " -2.14843750e-01 -8.74023438e-02  7.12890625e-02  1.87500000e-01\n",
      " -1.12304688e-01  2.73437500e-01 -3.26171875e-01 -1.77734375e-01\n",
      " -4.24804688e-02 -2.69531250e-01  6.64062500e-02 -6.88476562e-02\n",
      " -1.99218750e-01 -7.03125000e-02 -2.43164062e-01 -3.66210938e-02\n",
      " -7.37304688e-02 -1.77734375e-01  9.17968750e-02 -1.25000000e-01\n",
      " -1.65039062e-01 -3.57421875e-01 -2.85156250e-01 -1.66992188e-01\n",
      "  1.97265625e-01 -1.53320312e-01  2.31933594e-02  2.06054688e-01\n",
      "  1.80664062e-01 -2.74658203e-02 -1.92382812e-01 -9.61914062e-02\n",
      " -1.06811523e-02 -4.73632812e-02  6.54296875e-02 -1.25732422e-02\n",
      "  1.78222656e-02 -8.00781250e-02 -2.59765625e-01  9.37500000e-02\n",
      " -7.81250000e-02  4.68750000e-02 -2.22167969e-02  1.86767578e-02\n",
      "  3.11279297e-02  1.04980469e-02 -1.69921875e-01  2.58789062e-02\n",
      " -3.41796875e-02 -1.44042969e-02 -5.46875000e-02 -8.78906250e-02\n",
      "  1.96838379e-03  2.23632812e-01 -1.36718750e-01  1.75781250e-01\n",
      " -1.63085938e-01  1.87500000e-01  3.44238281e-02 -5.63964844e-02\n",
      " -2.27689743e-05  4.27246094e-02  5.81054688e-02 -1.07910156e-01\n",
      " -3.88183594e-02 -2.69531250e-01  3.34472656e-02  9.81445312e-02\n",
      "  5.63964844e-02  2.23632812e-01 -5.49316406e-02  1.46484375e-01\n",
      "  5.93261719e-02 -2.19726562e-01  6.39648438e-02  1.66015625e-02\n",
      "  4.56542969e-02  3.26171875e-01 -3.80859375e-01  1.70898438e-01\n",
      "  5.66406250e-02 -1.04492188e-01  1.38671875e-01 -1.57226562e-01\n",
      "  3.23486328e-03 -4.80957031e-02 -2.48046875e-01 -6.20117188e-02]\n"
     ]
    }
   ],
   "source": [
    "vec_computer = w2v['computer']\n",
    "print(vec_computer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key 'revature' not present\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mw2v\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrevature\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gensim\\models\\keyedvectors.py:403\u001b[0m, in \u001b[0;36mKeyedVectors.__getitem__\u001b[1;34m(self, key_or_keys)\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get vector representation of `key_or_keys`.\u001b[39;00m\n\u001b[0;32m    390\u001b[0m \n\u001b[0;32m    391\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    400\u001b[0m \n\u001b[0;32m    401\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key_or_keys, _KEY_TYPES):\n\u001b[1;32m--> 403\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey_or_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m vstack([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_vector(key) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m key_or_keys])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gensim\\models\\keyedvectors.py:446\u001b[0m, in \u001b[0;36mKeyedVectors.get_vector\u001b[1;34m(self, key, norm)\u001b[0m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_vector\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    423\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get the key's vector, as a 1D numpy array.\u001b[39;00m\n\u001b[0;32m    424\u001b[0m \n\u001b[0;32m    425\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    444\u001b[0m \n\u001b[0;32m    445\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 446\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m norm:\n\u001b[0;32m    448\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfill_norms()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gensim\\models\\keyedvectors.py:420\u001b[0m, in \u001b[0;36mKeyedVectors.get_index\u001b[1;34m(self, key, default)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m default\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 420\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not present\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Key 'revature' not present\""
     ]
    }
   ],
   "source": [
    "w2v['revature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'cup'\t'cup'\t1.00\n",
      "'cup'\t'bowl'\t0.40\n",
      "'cup'\t'beverage'\t0.27\n",
      "'cup'\t'cat'\t0.13\n"
     ]
    }
   ],
   "source": [
    "pairs = [\n",
    "    # Going from more similar to less similar \n",
    "    ('cup', 'cup'),\n",
    "    ('cup', 'bowl'),  \n",
    "    ('cup', 'beverage'),\n",
    "    ('cup', 'cat'),  \n",
    "]\n",
    "for w1, w2 in pairs:\n",
    "    print('%r\\t%r\\t%.2f' % (w1, w2, w2v.similarity(w1, w2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('coffee_mug', 0.6172524690628052), ('mugshot', 0.6114740371704102), ('mugs', 0.6063777804374695), ('pint_glass', 0.529857337474823), ('mugshots', 0.5195839405059814)]\n"
     ]
    }
   ],
   "source": [
    "print(w2v.most_similar(positive=['mug'], topn=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n"
     ]
    }
   ],
   "source": [
    "print(w2v.doesnt_match(['cup', 'cat', 'mug', 'jar']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Similarity: Cosine Similarity, Jaccard Similarity\n",
    "\n",
    "- Techniques like Word2Vec and GloVe gives us mathematical representations of texts, but how do they tell how similar/dissimilar they are?\n",
    "- Different Techniques:\n",
    "    - Euclidean Distance (how far apart are these vectors?)\n",
    "    - Cosine Similarity (The angle between the vectors)\n",
    "    - Jaccard Similarity (How many words do these texts share?)\n",
    "    - and more\n",
    "\n",
    "### Cosine Similarity\n",
    "One of the most common techniques. We calculate the angle between the two vectors.\n",
    "![cos_sim](https://memgraph.com/images/blog/cosine-similarity-python-scikit-learn/cosine-similarity.png)\n",
    "![cos_sim_formula](https://assets-global.website-files.com/5ef788f07804fb7d78a4127a/60dee7e4dec6611dc63cb158_dNiiYIrknDdfDwnqRpJ4n23givOOrrkWvlsBED9hE7qahtn_itdM1ziLQm0YYmqlV2j5q1Kur_icFc_K1jyYKIAcz_PBZ32OjpaFVQGAf41K3O0PhVRnnROFNnb_04jQ36VcX8pF.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.3.2-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\users\\junipersong\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.26.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\junipersong\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\junipersong\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.3.2)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Downloading scikit_learn-1.3.2-cp311-cp311-win_amd64.whl (9.2 MB)\n",
      "   ---------------------------------------- 0.0/9.2 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.2/9.2 MB 6.6 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.6/9.2 MB 9.4 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 1.4/9.2 MB 12.3 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 2.2/9.2 MB 15.3 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.2/9.2 MB 18.3 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 4.2/9.2 MB 20.6 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 4.8/9.2 MB 19.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 6.0/9.2 MB 21.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 7.1/9.2 MB 21.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.8/9.2 MB 21.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 8.9/9.2 MB 22.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.2/9.2 MB 22.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.2/9.2 MB 22.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.2/9.2 MB 22.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.2/9.2 MB 17.8 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: threadpoolctl, scikit-learn\n",
      "Successfully installed scikit-learn-1.3.2 threadpoolctl-3.2.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
      "[notice] To update, run: C:\\Users\\JuniperSong\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\junipersong\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.26.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
      "[notice] To update, run: C:\\Users\\JuniperSong\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# This is a python implementation of cosine similarity, using numpy\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    if len(vec1) != len(vec2) :\n",
    "        return None\n",
    "    \n",
    "    # Compute the dot product between 2 vectors\n",
    "    dot_prod = np.dot(vec1, vec2)\n",
    "    \n",
    "    # Compute the norms of the 2 vectors\n",
    "    norm_vec1 = np.sqrt(np.sum(vec1**2)) \n",
    "    norm_vec2 = np.sqrt(np.sum(vec2**2))\n",
    "    \n",
    "    # Compute the cosine similarity\n",
    "    # We divide the dot product of the 2 vectors by their length\n",
    "    cosine_similarity = dot_prod / (norm_vec1 * norm_vec2)\n",
    "    \n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 1 1 1 0 1 0 0]\n",
      " [1 0 1 0 1 1 1 1 1 1]]\n",
      "Cosine Similarity:\n",
      "0.4743416490252569\n"
     ]
    }
   ],
   "source": [
    "# Sample texts\n",
    "text1 = \"Natural language processing is fascinating.\"\n",
    "text2 = \"I'm intrigued by the wonders of natural language processing.\"\n",
    "\n",
    "# Tokenize and vectorize the texts\n",
    "vectorizer = CountVectorizer().fit_transform([text1, text2]).toarray()\n",
    "print(vectorizer)\n",
    "\n",
    "# Calculate cosine similarity\n",
    "cosine_sim = cosine_similarity(vectorizer[0, :], vectorizer[1, :])\n",
    "\n",
    "# Cosine Similarity ranges from -1 to 1, a number closer to 1 means that they are more similar\n",
    "print(\"Cosine Similarity:\")\n",
    "print(cosine_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaccard Index\n",
    "Jaccard Index, or Jaccard similarity coefficient, is used to guage the similarity between two sets.\n",
    "\n",
    "![jc_idx](https://wikimedia.org/api/rest_v1/media/math/render/svg/eaef5aa86949f49e7dc6b9c8c3dd8b233332c9e7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(set1, set2):\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "    return intersection / union if union != 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard Similarity: 0.3076923076923077\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "text1 = \"natural language processing is fascinating.\"\n",
    "text2 = \"I'm intrigued by the wonders of natural language processing.\"\n",
    "\n",
    "# Tokenize the sentences and turn them into sets\n",
    "set1 = set(word_tokenize(text1))\n",
    "set2 = set(word_tokenize(text2))\n",
    "\n",
    "# Calculate Jaccard similarity\n",
    "jaccard_sim = jaccard_similarity(set1, set2)\n",
    "\n",
    "# Print the Jaccard similarity\n",
    "print(f\"Jaccard Similarity: {jaccard_sim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HuggingFace\n",
    "- A company that focuses on fostering an open-source AI/ML community.\n",
    "- Originally a chatbot company built for teenagers (perhaps, hence the name and emoji) \n",
    "- Famous for their massive open-source collection of AI models and Transformer library\n",
    "- The platform we'll be using for our LLM's and Text Embedding Models.\n",
    "\n",
    "### Transformer Library\n",
    "- Library built for easy, low barrier interaction with various AI models\n",
    "- Transformer refers to a specific type of text-generation model that are context aware (like BERT or GPT), BUT in this context, HuggingFace's Transformer library has models beyond text-generation.\n",
    "- Benefits: Ease of Use, Flexibility, Simplicity\n",
    "- Tutorial: https://huggingface.co/learn/nlp-course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Install HuggingFace Transformer library\n",
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "# Got a windows machine and ran into an ERROR for not enabling long path? Run this line on PowerShell\n",
    "New-ItemProperty -Path \"HKLM:\\SYSTEM\\CurrentControlSet\\Control\\FileSystem\" `\n",
    "-Name \"LongPathsEnabled\" -Value 1 -PropertyType DWORD -Force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|██████████| 729/729 [00:00<00:00, 728kB/s]\n",
      "C:\\Users\\JuniperSong\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\JuniperSong\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "pytorch_model.bin: 100%|██████████| 1.62G/1.62G [01:41<00:00, 16.0MB/s]\n",
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "tokenizer_config.json: 100%|██████████| 52.0/52.0 [00:00<?, ?B/s]\n",
      "vocab.json: 100%|██████████| 899k/899k [00:00<00:00, 4.49MB/s]\n",
      "merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 2.00MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEUTRAL', 'score': 0.9694152474403381},\n",
       " {'label': 'NEUTRAL', 'score': 0.9525929689407349}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\", model=\"microsoft/deberta-large-mnli\")\n",
    "classifier([\"I'm so excited for the 3 day weekend!\", \"I love my cat\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember Tokenizing from the last 2 days?\n",
    "Well, we can't feed the models the raw text, so we have to tokenize our raw text the exact way the model was trained/expecting to receive input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': <tf.Tensor: shape=(2, 14), dtype=int32, numpy=\n",
      "array([[ 101, 1045, 1005, 2310, 2042, 3403, 2005, 2023, 5353, 2023, 2878,\n",
      "        3204, 1012,  102],\n",
      "       [ 101, 1045, 5223, 2023, 2061, 2172,  999,  102,    0,    0,    0,\n",
      "           0,    0,    0]])>, 'attention_mask': <tf.Tensor: shape=(2, 14), dtype=int32, numpy=\n",
      "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]])>}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "raw_inputs = [\n",
    "    \"I've been waiting for this weekend this whole month.\",\n",
    "    \"I hate this so much!\",\n",
    "]\n",
    "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"tf\")\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to gpt2 and revision 6c0e608 (https://huggingface.co/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "generation_config.json: 100%|██████████| 124/124 [00:00<?, ?B/s] \n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This weekend is three day weekend! I am going to be taking advantage of the opportunities that are available for me.\n",
      "\n",
      "This Sunday I am taking advantage of all the opportunities available to me to compete with other athletes in the world. All these challenges\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "text_generator = pipeline(\"text-generation\")\n",
    "generated_text = text_generator(\"This weekend is three day weekend! I am going to\")[0]['generated_text']\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "config.json: 100%|██████████| 1.80k/1.80k [00:00<?, ?B/s]\n",
      "pytorch_model.bin: 100%|██████████| 1.22G/1.22G [01:14<00:00, 16.5MB/s]\n",
      "tokenizer_config.json: 100%|██████████| 26.0/26.0 [00:00<?, ?B/s]\n",
      "vocab.json: 100%|██████████| 899k/899k [00:00<00:00, 2.95MB/s]\n",
      "merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 2.09MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Researchers and developers have made significant strides in creating sophisticated models that can understand and generate human-like text . The rapid progress in AI and NLP also raises ethical concerns and challenges . As the field continues to evolve, striking a balance between innovation and ethical responsibility becomes crucial .\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "long_text = \"\"\"\n",
    "In recent years, artificial intelligence (AI) has witnessed remarkable advancements, particularly in the field of natural language processing (NLP). Researchers and developers have made significant strides in creating sophisticated models that can understand and generate human-like text. One notable breakthrough is the development of transformer-based architectures, such as BERT and GPT-3, which have set new benchmarks in various NLP tasks.\n",
    "\n",
    "These models excel in tasks like sentiment analysis, text summarization, and language translation, showcasing their versatility. The widespread adoption of transformer models has led to the emergence of powerful tools and libraries, like the Transformers library by Hugging Face, making it easier for practitioners to leverage state-of-the-art models for their applications.\n",
    "\n",
    "However, the rapid progress in AI and NLP also raises ethical concerns and challenges. Issues like bias in language models, transparency in decision-making processes, and potential misuse of powerful AI technologies need careful consideration. As the field continues to evolve, striking a balance between innovation and ethical responsibility becomes crucial.\n",
    "\n",
    "In conclusion, the recent advancements in NLP, driven by transformer models and accessible libraries, have transformed the landscape of AI. While these technologies offer unprecedented capabilities, the ethical implications and responsible use of AI demand ongoing attention from the global community.\n",
    "\"\"\"\n",
    "summarizer = pipeline(\"summarization\")\n",
    "summary = summarizer(long_text)[0]['summary_text']\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other ways to use HuggingFace\n",
    "\n",
    "#### Hugging Face Inference API\n",
    "Hugging Face Inference API and Endpoint gives us access to the models hosted on huggingface via simple HTTP calls.\n",
    "Subtle but annoying Difference: HuggingFace Inference API: free version. HuggingFace Inference Endpoint: Paid, your own huggingface infra\n",
    "\n",
    "https://huggingface.co/spaces/HuggingFaceH4/zephyr-chat\n",
    "\n",
    "https://huggingface.co/HuggingFaceH4/zephyr-7b-beta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
