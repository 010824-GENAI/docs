{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 5: Introduction to Retrieval Augmented Generation\n",
    "- _This will be mostly conceptual_\n",
    "- _Projects applying week 1 concepts coming soon in next week_\n",
    "- _Disclaimer:_ This is a *very* new and actively developing field. Some of the information mentioned here may become stale in a few weeks/months.\n",
    "\n",
    "## Artificial Intelligence\n",
    "- computer systems that can perform tasks that typically require human intelligence\n",
    "- Ex. learning, reasoning, problem-solving, understanding natural language, and visual perception. \n",
    "\n",
    "## Machine Learning\n",
    "- Subset of AI\n",
    "- focuses on developing algorithms and statistical models without _explicit programming_\n",
    "- Rough steps:\n",
    "  - Prepare dataset\n",
    "  - Train the model\n",
    "  - Evaluate the model\n",
    "- Few of my favorite resources\n",
    "  - https://www.deeplearning.ai/short-courses/\n",
    "  - https://developers.google.com/machine-learning/crash-course\n",
    "\n",
    "### Training an LLM\n",
    "- Large Language Models are a type of AI Model that is trained to understand and generate text content. \n",
    "- These models are only as useful as the data they are trained on. They are trained with incredibly large amount of data. \n",
    "- Training one from the scratch, costs a lot of money and has a big environment impact.\n",
    "  - Training GPT-4 had the equivalent carbon footprint to \"driving a gasoline car for nearly 18 million miles or the equivalent of powering more than 1300 homes for one year\"\n",
    "    - https://www.linkedin.com/pulse/carbon-impact-large-language-models-ais-growing-cost-vaidheeswaran-fcbhc/\n",
    "  - The training process involves running thousands of GPUs over weeks or months\n",
    "  - Also this requires a team of ML experts\n",
    "  - Not something a regular ol' business would, or should, attempt (at least at this point in time)\n",
    "\n",
    "#### Issues with stock LLMs\n",
    "- Again, they are only as useful as the data they're trained on. So if they are not updated/trained regularly to keep up with the new data, they become stale.\n",
    "  - Try asking ChatGPT (on GPT 3.5) on LangChain\n",
    "- In a similar vein, they also don't have access to any business/private data\n",
    "- They are built for general purpose- they may not be as useful on domain/task specific usecases\n",
    "\n",
    "### Solution 1: Fine Tuning\n",
    "Process of training an already trained LLM for a specific use case\n",
    "\n",
    "#### Pros\n",
    "- Not as expensive as training one from scratch\n",
    "- Can be trained to be good at domain specific tasks \n",
    "  - Do you need an LLM that can understand a bunch of domain specific lingo, such as medical or legal?\n",
    "\n",
    "#### Cons\n",
    "- Still needs to be updated regularly with new data\n",
    "- Still needs at least intermediate ML knowledge to accomplish\n",
    "- We will Not be fine-tuning an LLM in this training\n",
    "- https://www.coursera.org/learn/generative-ai-with-llms\n",
    "\n",
    "\n",
    "### Solution 2: Retrieval Augmented Generation\n",
    "[RAG](https://www.pinecone.io/learn/retrieval-augmented-generation/)\n",
    "\n",
    "- An application architecture _utilizing_ LLMs\n",
    "- Combines a Retriever and a Generator in one architecture\n",
    "- Gives an LLM (either fine-tuned or stock) a domain/business-specific context/knowledge\n",
    "\n",
    "#### Pros\n",
    "- No training needed\n",
    "- Your data can be provided to the generator in real time\n",
    "- Cheap and Quick\n",
    "  - ML knowledge is nice but expertise is not necessary. We will be using LLMs, not training them.\n",
    "  - No need to pre-process, label, and do other tasks necessary for the data to be used on training\n",
    "- Reduces hallucination by providing factual/grounding context\n",
    "  - Hallucination is when LLM provides factually incorrect information that appears plausible\n",
    "    - This is because LLM really does not know what's true or not. It only knows the data its been trained on.\n",
    "    - Akin to Plato's \"Allegory of the Cave\"\n",
    "\n",
    "#### Cons\n",
    "- Still limited by the base LLM's ability\n",
    "- Still limited by the quality of data you provide\n",
    "- If the retrieved result is poor, the generation will be poor\n",
    "- Context Length Limitation\n",
    "  - Think of context as the working memory of LLM. If your input goes beyond it, it will truncate/forget it\n",
    "  - a known issue with LLMs\n",
    "\n",
    "**_Fine Tuning and RAG are not mutually exclusive. They can be used together- you can build a RAG application with a fine-tuned model that has the domain specific knowledge._**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
