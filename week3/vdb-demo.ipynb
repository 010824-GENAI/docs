{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the embedding model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial a list of sentences\n",
    "sentences = [\n",
    "    \"Birds fly over the rainbow\",\n",
    "    \"Why do birds suddenly appear\",\n",
    "    \"A fast brown animal leaps over a sleepy canine\",\n",
    "    \"The lazy dog lies under the shady tree\",\n",
    "    \"The quick brown fox jumps over the lazy dog\",\n",
    "]\n",
    "\n",
    "# Convert the sentences into vector (capturing semantic meaning)\n",
    "sentence_embeddings = model.encode(sentences)\n",
    "\n",
    "# print(f\"Vector Embeddings:\\n {sentence_embeddings}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the vector: (5, 384)\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "\n",
    "# Dimension of vectors\n",
    "# Dimension: represents the number of features or attributes encoded in the vector\n",
    "dim = sentence_embeddings.shape[1]\n",
    "\n",
    "print(f\"Shape of the vector: {sentence_embeddings.shape}\")\n",
    "\n",
    "# Create a Flat index\n",
    "# Uses L2 (Euclidean) distance to measure the similiarity between two vectors\n",
    "# IndexFlatL2 measures the L2 (or Euclidean) distance between all given points between our query vector, and the vectors loaded into the index. Itâ€™s simple, very accurate, but not too fast.\n",
    "index = faiss.IndexFlatL2(dim)\n",
    "\n",
    "# Add vectors to the index\n",
    "index.add(sentence_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: A dark fox jumping over dogs\n",
      "Most similar sentences in our index:\n",
      "- The quick brown fox jumps over the lazy dog\n",
      "- A fast brown animal leaps over a sleepy canine\n",
      "- Birds fly over the rainbow\n"
     ]
    }
   ],
   "source": [
    "query = \"A dark fox jumping over dogs\"\n",
    "\n",
    "# Convert the query into high dimensional vector (capturing semantic meaning)\n",
    "query_vector = model.encode([query])\n",
    "\n",
    "# Perform search\n",
    "# Return two numpy arrays: D (distances) and I (indices)\n",
    "# D is a 2D array of shape that contains the distances of the nearest neighbors. Each row corresponds to the distances of the k nearest neighbors of the corresponding query vector.\n",
    "# I is a 2D array of shape that contains the indices of the nearest neighbors. Each row corresponds to the indices of the k nearest neighbors of the corresponding query vector.   \n",
    "D, I = index.search(query_vector, k=3)  # Search for top 2 most similar sentences\n",
    "\n",
    "print(\"Query:\", query)\n",
    "print(\"Most similar sentences in our index:\")\n",
    "for i in I[0]:\n",
    "    print(\"-\", sentences[i])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
